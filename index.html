<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.1/css/all.min.css" integrity="sha256-Z1K5uhUaJXA7Ll0XrZ/0JhX4lAtZFpT6jkKrEDT0drU=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"fanmeiya.github.io","root":"/","images":"/images","scheme":"Pisces","darkmode":false,"version":"8.14.2","exturl":false,"sidebar":{"position":"left","width":330,"display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="路漫漫其修远兮，吾将上下而求索">
<meta property="og:type" content="website">
<meta property="og:title" content="FMY&#39;s blogs">
<meta property="og:url" content="http://fanmeiya.github.io/index.html">
<meta property="og:site_name" content="FMY&#39;s blogs">
<meta property="og:description" content="路漫漫其修远兮，吾将上下而求索">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="FMY">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://fanmeiya.github.io/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>FMY's blogs</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">FMY's blogs</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">归档</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
	  <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="FMY"
      src="/images/%E5%A4%B4%E5%83%8F.jpg">
  <p class="site-author-name" itemprop="name">FMY</p>
  <div class="site-description" itemprop="description">路漫漫其修远兮，吾将上下而求索 </div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">2</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
	  <iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=450 src="//music.163.com/outchain/player?type=0&id=2229469033&auto=1&height=430"></iframe>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://fanmeiya.github.io/2025/07/15/%E5%8D%8E%E4%B8%BAFusionCompute%E9%83%A8%E7%BD%B2ai4health%E9%A1%B9%E7%9B%AE/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/%E5%A4%B4%E5%83%8F.jpg">
      <meta itemprop="name" content="FMY">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FMY's blogs">
      <meta itemprop="description" content="路漫漫其修远兮，吾将上下而求索 ">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | FMY's blogs">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/07/15/%E5%8D%8E%E4%B8%BAFusionCompute%E9%83%A8%E7%BD%B2ai4health%E9%A1%B9%E7%9B%AE/" class="post-title-link" itemprop="url">华为FusionCompute部署</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-07-15 16:10:25" itemprop="dateCreated datePublished" datetime="2025-07-15T16:10:25+08:00">2025-07-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-07-16 11:07:09" itemprop="dateModified" datetime="2025-07-16T11:07:09+08:00">2025-07-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E9%83%A8%E7%BD%B2/" itemprop="url" rel="index"><span itemprop="name">部署</span></a>
        </span>
    </span>

  
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Changyan：</span>
    
    <a title="华为FusionCompute部署" href="/2025/07/15/%E5%8D%8E%E4%B8%BAFusionCompute%E9%83%A8%E7%BD%B2ai4health%E9%A1%B9%E7%9B%AE/#SOHUCS" itemprop="discussionUrl">
      <span id="sourceId::d182bdd89d1eb38ae15c3309235116a6" class="cy_cmt_count" itemprop="commentCount"></span>
    </a>
  </span>
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="虚拟机配置"><a href="#虚拟机配置" class="headerlink" title="虚拟机配置"></a>虚拟机配置</h2><ol>
<li><p>用模板24B-test-VM-06来创建虚拟机，注意若自定义密码要打开虚拟机后等待自定义虚拟机完成否则会是原模板的账号和密码<img src="/./../images/image-20250626213849399.png" alt="image-20250626213849399"></p>
</li>
<li><p>配置静态IP与DNS，注意分配的ip是否有人用过</p>
</li>
<li><p>配置GPU组（Atlas 300I Pro加速卡）</p>
</li>
<li><p>虚拟机登陆的账号和密码：root&#x2F;20011125fmy</p>
</li>
<li><p>查看系统版本：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">uname</span> <span class="token parameter variable">-m</span> <span class="token operator">&amp;&amp;</span> <span class="token function">cat</span> /etc/*release<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>查看的结果：</p>
<pre class="line-numbers language-txt" data-language="txt"><code class="language-txt">aarch64
DISTRIB_ID=Ubuntu
DISTRIB_RELEASE=20.04
DISTRIB_CODENAME=focal
DISTRIB_DESCRIPTION="Ubuntu 20.04 LTS"
NAME="Ubuntu"
VERSION="20.04 LTS (Focal Fossa)"
ID=ubuntu
ID_LIKE=debian
PRETTY_NAME="Ubuntu 20.04 LTS"
VERSION_ID="20.04"
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
VERSION_CODENAME=focal
UBUNTU_CODENAME=focal<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
</li>
<li><p>当虚拟机关闭后重启后vscode可能连不上，运行以下命令清除相关文件：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">rm</span> <span class="token parameter variable">-rf</span> ~/.vscode-server/        
<span class="token function">rm</span> <span class="token parameter variable">-rf</span> ~/.vscode-remote/  <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li>
</ol>
<h2 id="MindIE镜像"><a href="#MindIE镜像" class="headerlink" title="MindIE镜像"></a>MindIE镜像</h2><ol>
<li>下载的版本：1.0.RC3-300I-Duo-arm64,拉取镜像按照官网来（密码会变）,该镜像的cann版本为8.0.RC3：</li>
</ol>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@2c956aae23df:/<span class="token comment"># cd /usr/local/Ascend/ascend-toolkit/latest/aarch64-linux</span>
root@2c956aae23df:/usr/local/Ascend/ascend-toolkit/latest/aarch64-linux<span class="token comment"># cat ascend_toolkit_install.info</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<pre class="line-numbers language-txt" data-language="txt"><code class="language-txt">package_name=Ascend-cann-toolkit
version=8.0.RC3
innerversion=V100R001C19SPC001B155
compatible_version=[V100R001C13,V100R001C19],[V100R001C30]
arch=aarch64
os=linux
path=/usr/local/Ascend/ascend-toolkit/8.0.RC3/aarch64-linux<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>查找固件与驱动官网（<a target="_blank" rel="noopener" href="https://www.hiascend.com/hardware/firmware-drivers/community">社区版-固件与驱动-昇腾社区</a>）对应的版本，实际上用模板创建虚拟机自带的驱动刚好是对应的版本</p>
<p><img src="/./../images/image-20250626211845116.png" alt="image-20250626211845116"></p>
<p>该镜像下的python版本为3.11.10,torch版本为2.1.0,transformers版本为4.44.0</p>
<ol start="2">
<li>运行MindIE镜像命令</li>
</ol>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">docker</span> run <span class="token parameter variable">-it</span> <span class="token punctuation">\</span>
  <span class="token parameter variable">--name</span> mindie_container <span class="token punctuation">\</span>
  <span class="token parameter variable">--ipc</span><span class="token operator">=</span>host <span class="token punctuation">\</span>
  <span class="token parameter variable">--privileged</span> <span class="token punctuation">\</span>
  <span class="token parameter variable">-p</span> <span class="token number">8000</span>:8000 <span class="token punctuation">\</span>
  <span class="token parameter variable">-p</span> <span class="token number">8001</span>:8001 <span class="token punctuation">\</span>
  <span class="token parameter variable">--device</span><span class="token operator">=</span>/dev/davinci0 <span class="token punctuation">\</span>
  <span class="token parameter variable">--device</span><span class="token operator">=</span>/dev/davinci2 <span class="token punctuation">\</span>
  <span class="token parameter variable">--device</span><span class="token operator">=</span>/dev/davinci4 <span class="token punctuation">\</span>
  <span class="token parameter variable">--device</span><span class="token operator">=</span>/dev/davinci_manager <span class="token punctuation">\</span>
  <span class="token parameter variable">--device</span><span class="token operator">=</span>/dev/devmm_svm <span class="token punctuation">\</span>
  <span class="token parameter variable">--device</span><span class="token operator">=</span>/dev/hisi_hdc <span class="token punctuation">\</span>
  <span class="token parameter variable">-v</span> /usr/local/Ascend/driver:/usr/local/Ascend/driver:ro <span class="token punctuation">\</span>
  <span class="token parameter variable">-v</span> /usr/local/dcmi:/usr/local/dcmi <span class="token punctuation">\</span>
  <span class="token parameter variable">-v</span> /usr/local/bin/npu-smi:/usr/local/bin/npu-smi:ro <span class="token punctuation">\</span>
  <span class="token parameter variable">-v</span> /etc/ascend_install.info:/etc/ascend_install.info <span class="token punctuation">\</span>
  <span class="token parameter variable">-v</span> /etc/vnpu.cfg:/etc/vnpu.cfg <span class="token punctuation">\</span>
  <span class="token parameter variable">-v</span> /home/Datasets/Hf_model:/home/Datasets/Hf_model <span class="token punctuation">\</span>
  <span class="token parameter variable">-v</span> /root/ai4health/webapp_all:/workspace/webapp_all <span class="token punctuation">\</span>
  swr.cn-south-1.myhuaweicloud.com/ascendhub/mindie:1.0.RC3-300I-Duo-arm64 <span class="token punctuation">\</span>
  <span class="token function">bash</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>一般修改以下字段：</p>
<pre class="line-numbers language-none"><code class="language-none">--name：自己取的容器名字
--p:端口映射
--device:设备挂载,一般10-12行不变，其他的需要用命令确定：ls &#x2F;dev | grep davinci
-v ：目录与文件挂载，一般13-17都不变
swr.cn-south-1.myhuaweicloud.com&#x2F;ascendhub&#x2F;mindie:1.0.RC3-300I-Duo-arm64：实际用的 MindIE 镜像（下载时会看到）<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>



<ol start="3">
<li>容器运行后可解压atb-models（mindIE llm和mindie service 会用到）：</li>
</ol>
<p>先创建解压后的目录：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">mkdir</span> <span class="token parameter variable">-p</span> /usr/local/Ascend/atb-models<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p><img src="/./../images/image-20250626174546963.png" alt="image-20250626174546963"></p>
<p>注意有多个版本，根据torch的版本和当前的 PyTorch&#x2F;torch_npu 是用哪一种 C++ ABI 编译,要确定是用什么编译的用以下代码：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch
flag <span class="token operator">=</span> torch<span class="token punctuation">.</span>compiled_with_cxx11_abi<span class="token punctuation">(</span><span class="token punctuation">)</span>   <span class="token comment"># True → abi1, False → abi0</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>确定后再解压对应的文件：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">tar</span> <span class="token parameter variable">-xzvf</span> /opt/package/Ascend-mindie-atb-models_1.0.RC3_linux-aarch64_torch2.1.0-abi0.tar.gz <span class="token parameter variable">-C</span> /usr/local/Ascend/atb-models/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<ol start="4">
<li>退出容器命令：exit</li>
</ol>
<p>启动已退出的容器</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">docker</span> start mindie_container<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<ol start="5">
<li>进入容器交互</li>
</ol>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">docker</span> <span class="token builtin class-name">exec</span> <span class="token parameter variable">-it</span> mindie_container <span class="token function">bash</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<ol start="6">
<li>若退出后重新进入容器，则需要重新加载 CANN 环境变量，执行以下三行命令。</li>
</ol>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token builtin class-name">source</span> /usr/local/Ascend/ascend-toolkit/set_env.sh
<span class="token builtin class-name">source</span> /usr/local/Ascend/mindie/set_env.sh
<span class="token builtin class-name">source</span> /usr/local/Ascend/llm_model/set_env.sh<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<ol start="7">
<li>删除容器：</li>
</ol>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">docker</span> stop mindie_container<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">docker</span> <span class="token function">rm</span> mindie_container<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>



<p>模型权重下载命令</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token builtin class-name">export</span> <span class="token assign-left variable">HF_ENDPOINT</span><span class="token operator">=</span>https://hf-mirror.com
huggingface-cli download Qwen/Qwen2.5-VL-3B-Instruct --resume-download --local-dir /home/Datasets/Hf_model/Qwen2.5-VL-3B-Instruct --local-dir-use-symlinks False <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>mindIE llm （<a target="_blank" rel="noopener" href="https://www.hiascend.com/document/detail/zh/mindie/20RC1/mindiellm/llmdev/mindie_llm0001.html">简介-MindIE2.0.RC1-昇腾社区</a>）和mindIE service（<a target="_blank" rel="noopener" href="https://www.hiascend.com/document/detail/zh/mindie/20RC1/mindieservice/servicedev/mindie_service0001.html">简介-MindIE2.0.RC1-昇腾社区</a>）来推理参考官网步骤，需要注意对要进行推理的模型权重存放文件进行权限设置，否则会出问题，以下是权限设置和检查示例：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@34cc163c2663:/usr/local/Ascend/mindie/1.0.RC3/mindie-service<span class="token comment"># ls -l /home/Datasets/Hf_model/Qwen2.5-7B-Instruct/config.json</span>
-rw-r--r-- <span class="token number">1</span> root root <span class="token number">663</span> Jun <span class="token number">25</span> 03:23 /home/Datasets/Hf_model/Qwen2.5-7B-Instruct/config.json
root@34cc163c2663:/usr/local/Ascend/mindie/1.0.RC3/mindie-service<span class="token comment"># chmod 640 /home/Datasets/Hf_model/Qwen2.5-7B-Instruct/config.json</span>
root@34cc163c2663:/usr/local/Ascend/mindie/1.0.RC3/mindie-service<span class="token comment"># ls -l /home/Datasets/Hf_model/Qwen2.5-7B-Instruct/config.json</span>
-rw-r----- <span class="token number">1</span> root root <span class="token number">663</span> Jun <span class="token number">25</span> 03:23 /home/Datasets/Hf_model/Qwen2.5-7B-Instruct/config.json<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>用mindie llm来进行推理： </p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token builtin class-name">cd</span> usr/local/Ascend/llm_model/
<span class="token function">bash</span> examples/models/qwen/run_fa.sh <span class="token parameter variable">-m</span> /home/Datasets/Hf_model/Qwen2.5-7B-Instruct <span class="token parameter variable">-c</span> <span class="token boolean">true</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p><strong>主机上安装 Redis</strong>:</p>
<pre class="line-numbers language-none"><code class="language-none">sudo apt install -y redis-server<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p><strong>启动Redis并设置开机自启</strong></p>
<pre class="line-numbers language-none"><code class="language-none">sudo systemctl start redis-server
sudo systemctl enable redis-server<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p><strong>容器内安装redis</strong>:	</p>
<pre class="line-numbers language-bash1" data-language="bash1"><code class="language-bash1">更新索引：apt-get update

再安装 Redis：apt-get install -y redis-server

启动 Redis（容器里通常没有 systemd）：redis-server --daemonize yes或者直接前台跑：redis-server<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>开启数据库网页命令：</p>
<p>sqlite_web –host 0.0.0.0 -p 8001 &#x2F;workspace&#x2F;webapp_all&#x2F;db.sqlite3  ，一定要直接指定文件的全路径，这样无论你当前在哪个目录，它都能打开真正的 DB</p>
<p>后台运行相关项目文件命令：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">nohup</span> ./start_workers.sh <span class="token operator">></span>worker.log <span class="token operator"><span class="token file-descriptor important">2</span>></span><span class="token file-descriptor important">&amp;1</span> <span class="token operator">&amp;</span>
<span class="token function">nohup</span> python manage.py runserver <span class="token number">0.0</span>.0.0:8000 <span class="token operator">></span> django_dev.log <span class="token operator"><span class="token file-descriptor important">2</span>></span><span class="token file-descriptor important">&amp;1</span> <span class="token operator">&amp;</span>
<span class="token function">nohup</span> sqlite_web <span class="token parameter variable">--host</span> <span class="token number">0.0</span>.0.0 <span class="token parameter variable">-p</span> <span class="token number">8001</span> /workspace/webapp_all/db.sqlite3 <span class="token operator">></span> sqlite_web.log <span class="token operator"><span class="token file-descriptor important">2</span>></span><span class="token file-descriptor important">&amp;1</span> <span class="token operator">&amp;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>彻底终止celery相关的程序：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">pkill</span> <span class="token parameter variable">-9</span> <span class="token parameter variable">-f</span> <span class="token string">"celery.*worker"</span> <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>npu设置可见的npu键名为：ASCEND_RT_VISIBLE_DEVICES；GPU是CUDA_VISIBLE_DEVICES</p>
<table>
<thead>
<tr>
<th>变量</th>
<th>主要受众</th>
<th>生效范围</th>
</tr>
</thead>
<tbody><tr>
<td><code>ASCEND_VISIBLE_DEVICES</code></td>
<td>npu-smi、驱动日志</td>
<td><strong>监控与日志工具</strong></td>
</tr>
<tr>
<td><code>ASCEND_RT_VISIBLE_DEVICES</code> (<code>NPU_VISIBLE_DEVICES</code>)</td>
<td>Ascend Runtime、torch-npu、MindSpore、TensorFlow-Ascend</td>
<td></td>
</tr>
</tbody></table>
<p>运行过程中发现GPU的AICore始终为0，可添加以下代码到推理脚本前面然后发现AICore有数字了：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">torch_npu<span class="token punctuation">.</span>npu<span class="token punctuation">.</span>set_compile_mode<span class="token punctuation">(</span>jit_compile<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>	<span class="token operator">//</span>设置模型编译时是否优先在线编译，默认为true
<span class="token keyword">from</span> torch_npu<span class="token punctuation">.</span>npu<span class="token punctuation">.</span>amp <span class="token keyword">import</span> autocast              <span class="token operator">//</span>混合精度<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p><img src="/./../images/image-20250626210406385.png" alt="image-20250626210406385"></p>
<p>更新数据库命令：</p>
<pre class="line-numbers language-none"><code class="language-none">python manage.py makemigrations
python manage.py migrate<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>


      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://fanmeiya.github.io/2025/07/10/Medical-reasoning-task/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/%E5%A4%B4%E5%83%8F.jpg">
      <meta itemprop="name" content="FMY">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FMY's blogs">
      <meta itemprop="description" content="路漫漫其修远兮，吾将上下而求索 ">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | FMY's blogs">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/07/10/Medical-reasoning-task/" class="post-title-link" itemprop="url">Medical-reasoning-task(1)</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-07-10 16:10:25" itemprop="dateCreated datePublished" datetime="2025-07-10T16:10:25+08:00">2025-07-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-07-18 11:14:16" itemprop="dateModified" datetime="2025-07-18T11:14:16+08:00">2025-07-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/LLM/" itemprop="url" rel="index"><span itemprop="name">LLM</span></a>
        </span>
    </span>

  
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Changyan：</span>
    
    <a title="Medical-reasoning-task(1)" href="/2025/07/10/Medical-reasoning-task/#SOHUCS" itemprop="discussionUrl">
      <span id="sourceId::420e19d30fc67101cf73d5434d4c1209" class="cy_cmt_count" itemprop="commentCount"></span>
    </a>
  </span>
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="1、医学基准测试"><a href="#1、医学基准测试" class="headerlink" title="1、医学基准测试"></a>1、医学基准测试</h2><p><img src="/./../images/image-20250710163204802.png" alt="image-20250710163204802"></p>
<p>DiagnosisArena:</p>
<p>全面具有挑战的基准测试，评估LLMs临床诊断推理能力，从各个顶级医学期刊中收集临床病例报告，将其划分为病例信息、体格检查、诊断测试以及最终诊断，通过各种AI、专家的筛选去掉简单、模糊的病例。gpt-4o作为评估模型，有两种形式的评估：开放式和多项选择题，研究发现将诊断任务转换为多项选择格式后，模型性能显著提升。</p>
<ul>
<li><strong>具体案例分析</strong>：通过分析一个具体病例，探讨当前推理模型在解决复杂诊断问题时的局限性。例如，DeepSeek-R1在诊断“附属二尖瓣组织”时，忽略了多个间接证据，过度依赖常见疾病的推理路径，导致诊断错误。</li>
<li><strong>模型局限性</strong>：当前的LLMs尚未完全适应临床诊断场景中的复杂推理需求。这些模型在处理复杂临床问题时，仍然依赖于知识记忆，而不是深入理解和推理关键细节。</li>
</ul>
<p>Automating Expert-Level Medical Reasoning  Evaluation of Large Language Models：</p>
<p>论文提出了一个名为MedThink-Bench的基准，旨在对LLMs的医学推理进行严格、可解释且可扩展的评估，并提出了一个名为LLM-w-Ref的评估框架，该框架结合了专家精心策划的细粒度推理和LLM-as-a-Judge机制，以专家级的保真度评估中间推理，同时保持可扩展性。</p>
<p>构建MedThink-Bench基准：</p>
<ul>
<li><p><strong>数据收集</strong>：从十个公开可用的医学问答数据集中收集了500个复杂的医学问题，这些问题覆盖了十个医学领域，包括病理学、出院、疾病诊断、解剖学与生理学、治疗、公共卫生、政策与伦理、预后、诊断检查和药理学。</p>
<p><strong>数据预处理</strong>：去除了重复条目和涉及医学图像的问题。</p>
<p><strong>专家注释</strong>：由十名医学专家组成的团队对问题进行注释，将其分为十个不同的医学领域，并通过共识协作生成细粒度的推理轨迹。这些推理轨迹反映了真实世界的临床逻辑。</p>
</li>
<li><p>提出LLM-w-Ref评估框架：<strong>结合细粒度推理和LLM-as-a-Judge机制</strong>：该框架利用MedThink-Bench中的专家精心策划的细粒度推理和LLM-as-a-Judge机制，结合了两者的优点。通过使用专家注释的推理轨迹来校准基于LLM的评估器，该框架可以准确地评估中间推理，以实现专家级的事实一致性，同时实现可扩展的评估。</p>
</li>
</ul>
<h2 id="2、相关论文"><a href="#2、相关论文" class="headerlink" title="2、相关论文"></a>2、相关论文</h2><h3 id="2-1-HuatuoGPT-o1：这是一个能够进行复杂推理的医疗LLM"><a href="#2-1-HuatuoGPT-o1：这是一个能够进行复杂推理的医疗LLM" class="headerlink" title="2.1 HuatuoGPT-o1：这是一个能够进行复杂推理的医疗LLM"></a>2.1 HuatuoGPT-o1：这是一个能够进行复杂推理的医疗LLM</h3><p>通过以下几个步骤解决在大型语言模型（LLMs）中增强医疗领域复杂推理能力的问题：</p>
<ol>
<li>构建可验证的医疗问题</li>
</ol>
<ul>
<li><strong>选择和转换问题</strong>：从现有的医疗考试问题中筛选出具有挑战性、需要深入推理的问题，并将其从选择题格式转换为开放式问题，每个问题都有唯一的、客观的真实答案，以便于验证模型的输出。</li>
</ul>
<ol start="2">
<li>开发医疗验证器</li>
</ol>
<ul>
<li><strong>验证模型输出</strong>：使用一个基于LLM的验证器来检查模型生成的答案是否与真实答案匹配，提供正确的反馈。</li>
</ul>
<ol start="3">
<li>两阶段方法</li>
</ol>
<p>第一阶段：学习复杂推理</p>
<ul>
<li><strong>搜索正确轨迹</strong>：利用验证器的反馈来引导模型通过策略搜索找到正确的推理路径，如果初始推理被拒绝，则应用不同的策略（如回溯、探索新路径、验证和纠正）来迭代改进答案。</li>
<li><strong>构建SFT训练数据</strong>：将成功的推理路径重构为连贯的自然语言推理过程（复杂CoT），用于监督式微调（Supervised Fine-Tuning, SFT），以教会模型在回答前进行深入思考。</li>
</ul>
<p>第二阶段：通过强化学习增强复杂推理<strong>强化学习（RL）</strong>：在第一阶段学习到的复杂推理技能基础上，使用基于验证器反馈的稀疏奖励来引导模型自我改进，使用Proximal Policy Optimization（PPO）算法进行策略优化。</p>
<h3 id="2-2-DoctorRAG-旨在解决现有医疗检索增强型生成（RAG）系统在处理复杂医疗任务时的局限性。"><a href="#2-2-DoctorRAG-旨在解决现有医疗检索增强型生成（RAG）系统在处理复杂医疗任务时的局限性。" class="headerlink" title="2.2 DoctorRAG:旨在解决现有医疗检索增强型生成（RAG）系统在处理复杂医疗任务时的局限性。"></a>2.2 DoctorRAG:旨在解决现有医疗检索增强型生成（RAG）系统在处理复杂医疗任务时的局限性。</h3><p>现有的医疗 RAG 系统主要依赖于医学知识库中的知识，忽视了从类似患者案例中获得的经验性知识。生成模型的输出需要经过严格的验证，以确保它们不仅相关，而且与检索到的医疗背景信息一致，这需要一个专门的机制来进行迭代细化和验证。</p>
<p>具体来说，该框架通过以下两个主要阶段解决问题：</p>
<ol>
<li>Expertise-Experience retrieval and aggregation（专业知识与经验检索与聚合）</li>
</ol>
<ul>
<li><strong>知识库（Knowledge Base, K）</strong>：从多个医学知识源中构建，这些源首先被分割成文本块，然后转换成声明句，并标注上医学概念标识符。这样，知识库中的每个条目都包含一个声明句和一组相关的医学概念。</li>
<li><strong>患者库（Patient Base, P）</strong>：包含去识别化的患者记录，每条记录包括患者的主诉或临床对话、结构化的临床数据以及辅助元数据。</li>
<li><strong>查询处理</strong>：对于一个用户查询，系统首先通过查询标注代理（Query Tagging Agent）为其标注相关的医学概念标识符，然后将查询嵌入到与知识库和患者库相同的向量空间中。</li>
<li><strong>检索机制</strong>：系统从知识库中检索与查询概念匹配且语义相似的声明句，从患者库中检索与查询向量相似的患者记录。检索到的知识和患者记录被聚合起来，形成一个统一的上下文，作为生成模块的输入。</li>
</ul>
<ol start="2">
<li>Iterative answer optimization with multi-agent Med-TextGrad（多智能体 Med-TextGrad 的迭代答案优化）</li>
</ol>
<ul>
<li><strong>Med-TextGrad 框架</strong>：该框架通过多智能体文本梯度优化过程来迭代地改进生成的答案。它包括生成器（Generator）、上下文标准（Context Criterion）、患者标准（Patient Criterion）以及上下文优化器（Context Optimizer）和患者优化器（Patient Optimizer）。</li>
<li><strong>文本梯度计算与反向传播</strong>：生成的答案首先被上下文标准和患者标准评估，产生文本形式的批评意见。这些批评意见被用来计算答案级别的文本梯度，然后进一步计算提示级别的文本梯度。这些梯度通过文本梯度下降步骤（Textual Gradient Descent, TGD）更新提示，从而在下一次迭代中生成更优的答案。</li>
<li><strong>迭代优化</strong>：这个过程会持续进行预定的迭代次数，或者直到满足某种收敛条件（例如，批评意见或答案的变化最小化）。</li>
</ul>
<h3 id="2-3-MedDreamer：一种专为临床决策设计的两阶段模型-based-强化学习框架。"><a href="#2-3-MedDreamer：一种专为临床决策设计的两阶段模型-based-强化学习框架。" class="headerlink" title="2.3 MedDreamer：一种专为临床决策设计的两阶段模型-based 强化学习框架。"></a>2.3 MedDreamer：一种专为临床决策设计的两阶段模型-based 强化学习框架。</h3><p>作者把复杂、稀疏又不规则的电子病历数据先映射到一个更干净、更结构化的潜在空间，再靠“想象”虚拟病人轨迹来训练策略，从而在不伤及真实病人的前提下学会更优的治疗方案。</p>
<p>关键创新：</p>
<table>
<thead>
<tr>
<th>组件</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td><strong>AFI 模块</strong></td>
<td>自适应特征整合；把原始数值 + 时间间隔一起编码，显式建模缺失与不规则采样</td>
</tr>
<tr>
<td><strong>潜在世界模型</strong></td>
<td>基于 RSSM + 离散潜变量，先学会“病人如何演化”</td>
</tr>
<tr>
<td><strong>两阶段训练</strong></td>
<td><strong>阶段1</strong>：真实轨迹 + 少量短期想象，保证策略“脚踏实地” <strong>阶段2</strong>：从每个中间状态起完全想象，鼓励探索、超越历史</td>
</tr>
<tr>
<td><strong>安全混合回放</strong></td>
<td>真实与想象样本按比例混合，既保持临床可信，又能跳出医生的次优决策</td>
</tr>
</tbody></table>
<p>数据集：败血症用药（Sepsis）：MIMIC-IV 21 233 名成人患者；机械通气设置（MV）：eICU 21 595 例 ≥ 24 h 通气患者</p>
<p>奖励：终点奖励（死&#x2F;活）+中间奖励，用关键生理指标提供及时反馈：指标变好立刻奖励，变坏立刻惩罚</p>
<p><img src="/./../images/image-20250711154221051.png" alt="image-20250711154221051"></p>
<p>评估指标：</p>
<p>**定量指标 **</p>
<ol>
<li><strong>V_CWPDIS（Cumulative Weighted Per Decision Importance Sampling）</strong></li>
</ol>
<ul>
<li><strong>中文解释</strong>：累计加权逐步重要性采样。</li>
<li><strong>为什么要用？</strong><ul>
<li>现实中不能直接在真实ICU让AI随意试验新方案，所以只能用<strong>离线策略评估</strong>（off-policy evaluation, OPE）。</li>
</ul>
</li>
<li><strong>原理</strong>：<ul>
<li>回放每条历史病人轨迹时，如果AI策略跟医生选择一致，给这个奖励更高权重；若很少选同样动作，则奖励被弱化。</li>
<li>还引入“折扣因子”γ，使得近期的奖励影响更大（避免后面累计噪声太大）。</li>
</ul>
</li>
<li><strong>类比举例</strong>：<ul>
<li>假设医生历史轨迹为A→B→C，AI决策为A→B→D。</li>
<li>只有A、B重合时的奖励才有高权重，D与C不同则那步奖励加权很低。</li>
</ul>
</li>
<li><strong>结果</strong>：得出“如果全体病人都按AI推荐治疗，预期回报是多少”。</li>
</ul>
<ol start="2">
<li><strong>ESS（Effective Sampling Size，有效样本量）</strong></li>
</ol>
<ul>
<li><strong>中文解释</strong>：有多少“有效轨迹”真正参与了V_CWPDIS的计算。</li>
<li><strong>原理</strong>：如果AI策略和医生历史动作很接近，大多数轨迹都能参与，ESS高；反之ESS低，评估就不稳。</li>
<li><strong>用法</strong>：ESS越大，评估越可靠；ESS很小，则这个OPE的结果很可能是噪声。</li>
</ul>
<ol start="3">
<li><strong>Mortality Rate &amp; RM（死亡率和相对死亡率）</strong></li>
</ol>
<ul>
<li><p>**EM (Estimated Mortality)**：用世界模型&#x2F;OPE方法评估，如果大家都按AI方案治疗，会有多少人“可能死亡”。</p>
</li>
<li><p>**CM (Clinician Mortality)**：历史上医生治疗下的实际死亡率。</p>
</li>
<li><p>**RM (Relative Mortality)**：<br>$$<br>RM &#x3D; \frac{EM - CM}{CM}<br>$$</p>
<ul>
<li>正值：AI方案死亡率高于医生，不好。</li>
<li>负值：AI方案死亡率低于医生，说明有进步。</li>
</ul>
</li>
</ul>
<p>**定性指标 **</p>
<ol start="4">
<li><strong>Episode Return（轨迹回报）</strong></li>
</ol>
<ul>
<li><strong>AI episode return</strong>：用AI策略，每一步都“假想”选一次动作，然后计算整条轨迹奖励总和。</li>
<li><strong>Imagined episode return</strong>：用世界模型完全想象一条“新轨迹”，累计奖励。</li>
<li><strong>意义</strong>：衡量整个治疗周期内，AI决策带来的健康获益（奖励高，策略好）。</li>
</ul>
<ol start="5">
<li><strong>Mortality vs Return（回报与死亡率的关系）</strong></li>
</ol>
<ul>
<li><strong>理想现象</strong>：好策略应该“回报高，死亡率低”。</li>
<li><strong>具体做法</strong>：把不同轨迹的总回报和实际&#x2F;估计死亡率画成图，看是否呈现出“回报越高，死亡越少”的趋势。</li>
<li><strong>区分</strong>：<ul>
<li>Model-free：用Q值估算每步回报。</li>
<li>Model-based：直接用episode return对比每条轨迹的死亡率。</li>
</ul>
</li>
</ul>
<ol start="6">
<li><strong>Action Distribution（动作分布）</strong></li>
</ol>
<ul>
<li>统计AI&#x2F;医生选择的各种用药组合出现频率。</li>
<li>用于分析AI策略是否合理（比如是否过于极端&#x2F;保守）。</li>
</ul>
<ol start="7">
<li><strong>Mortality vs Action Difference（死亡率与动作偏离）</strong></li>
</ol>
<ul>
<li>计算AI和医生每一步用药剂量的“差值”，统计这种偏离下的死亡率。</li>
<li>理想现象：当AI与医生动作一致时，死亡率低；偏离很大时，死亡率升高，形成“V型”趋势。说明AI决策和医生高度一致时最安全，偶尔探索偏离时风险会升高。</li>
</ul>
<h3 id="2-4-Med-PRM-一个基于检索增强生成的过程奖励建模框架，通过检索临床指南和文献中的证据来验证每个推理步骤，从而实现对推理质量的细粒度评估。"><a href="#2-4-Med-PRM-一个基于检索增强生成的过程奖励建模框架，通过检索临床指南和文献中的证据来验证每个推理步骤，从而实现对推理质量的细粒度评估。" class="headerlink" title="2.4 Med-PRM:一个基于检索增强生成的过程奖励建模框架，通过检索临床指南和文献中的证据来验证每个推理步骤，从而实现对推理质量的细粒度评估。"></a>2.4 Med-PRM:一个基于检索增强生成的过程奖励建模框架，通过检索临床指南和文献中的证据来验证每个推理步骤，从而实现对推理质量的细粒度评估。</h3><ol>
<li><strong>检索增强的过程奖励建模（RAG-AS-A-JUDGE）</strong></li>
</ol>
<ul>
<li><strong>检索相关医学知识</strong>：<ul>
<li>Med-PRM 使用检索增强生成（RAG）技术，从临床指南和医学文献中检索与问题相关的证据。这些证据为模型提供了丰富的医学背景知识，帮助其生成基于事实的推理。</li>
<li>检索过程使用了MedCPT（Jin et al., 2023）的双编码器和交叉编码器，从四个生物医学语料库中检索文档：<ul>
<li>临床指南</li>
<li>StatPearls</li>
<li>医学教科书</li>
<li>罕见疾病语料库</li>
</ul>
</li>
</ul>
</li>
<li><strong>步骤级评估</strong>：<ul>
<li>Med-PRM 通过 RAG-AS-A-JUDGE 方法对每个推理步骤进行二元分类，判断其是否正确。这与传统的基于最终结果的奖励模型（ORM）不同，后者仅根据最终答案的正确性来评估整个推理轨迹。</li>
<li>每个步骤的标签 通过一个大型语言模型（LLM）生成，该模型结合了问题、推理轨迹和检索到的文档，以确保评估的准确性和医学背景的一致性。</li>
</ul>
</li>
</ul>
<ol start="2">
<li><strong>训练过程</strong></li>
</ol>
<ul>
<li><strong>数据过滤和标注</strong>：<ul>
<li>训练数据来自 MedQA、MedMCQA、PubMedQA 和 MMLU 等医学问答数据集。对于每个问题，生成多个候选推理轨迹，并过滤掉步骤过少或过多的轨迹。</li>
<li>为了保持标签平衡，每个问题的正确推理轨迹数量不超过错误轨迹数量的两倍。</li>
<li>检索到的文档被截断并附加到问题和推理轨迹之前，形成输入。每个步骤的二元标签由 RAG-AS-A-JUDGE 生成，用于过程级监督。</li>
</ul>
</li>
<li><strong>奖励模型训练</strong>：<ul>
<li>Med-PRM 使用交叉熵损失函数来训练奖励模型，目标是最小化所有推理步骤的预测标签和真实标签之间的差异。</li>
<li>模型输入包括问题、检索到的文档和推理轨迹，输出为每个步骤的置信度分数 。</li>
</ul>
</li>
</ul>
<ol start="3">
<li><strong>测试时推理（Test-time Inference）</strong></li>
</ol>
<ul>
<li>推理轨迹选择<ul>
<li>在测试时，Med-PRM 可以作为验证器，与经过微调的策略模型一起使用。策略模型生成多个推理轨迹，Med-PRM 为每个轨迹分配一个分数，选择分数最高的轨迹作为最终答案。</li>
<li>论文中使用了两种策略：Best-of-N 和 SC+RM（Self-Consistency + Reward Model）。Best-of-N 选择分数最高的轨迹，而 SC+RM 结合了自一致性（Self-Consistency）和奖励模型评分，选择总奖励分数最高的答案。</li>
</ul>
</li>
</ul>
<ol start="4">
<li><strong>策略模型微调（Policy Model Fine-tuning）</strong></li>
</ol>
<ul>
<li>拒绝采样<ul>
<li>Med-PRM 还可以用于微调策略模型。在训练过程中，策略模型生成多个推理轨迹，Med-PRM 为每个轨迹分配步骤级奖励分数。</li>
<li>只有分数最高的轨迹被保留用于监督微调，从而提高模型在复杂医学问答任务上的性能。</li>
</ul>
</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>





</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">FMY</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  




  




<script class="next-config" data-name="changyan" type="application/json">{"enable":true,"appid":"cywygO4ii","appkey":"0ef7f9e4f5618b09ce9abda1c5964730","count":true}</script>
<script src="/js/third-party/comments/changyan.js"></script>

</body>
</html>
